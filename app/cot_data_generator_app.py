"""CoTæ•°æ®æ‰¹é‡ç”Ÿæˆå·¥å…·

è‡ªåŠ¨åŒ–æ‰¹é‡ç”ŸæˆCoTæ•°æ®ï¼Œæ”¯æŒä»»åŠ¡é˜Ÿåˆ—ã€å¹¶è¡Œå¤„ç†ã€è¿›åº¦ç›‘æ§å’Œæ•°æ®éªŒè¯ã€‚
"""
import os
import sys
import json
import time
import argparse
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from pathlib import Path
import concurrent.futures
import threading
from queue import Queue

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from algorithm.cot_data_generator_with_recorder import create_cot_data_generator_with_recorder
from infrastructure.storage.cot_data_recorder import BatchCoTDataRecorder, create_batch_cot_data_recorder
from infrastructure.llm.deepseek_client import DeepSeekClient
from infrastructure.planner.lama_planner import LAMAPlanner
from config.settings import Settings
from config.data_schema import CoTDataPoint, validate_cot_data


class CoTDataBatchGenerator:
    """CoTæ•°æ®æ‰¹é‡ç”Ÿæˆå™¨"""
    
    def __init__(
        self,
        config: Optional[Dict[str, Any]] = None,
        output_dir: Optional[str] = None,
        max_workers: int = 3,
        use_sandbox: bool = True  # é»˜è®¤å¯ç”¨æ²™ç›’
    ):
        """
        åˆå§‹åŒ–æ‰¹é‡ç”Ÿæˆå™¨
        
        :param config: é…ç½®å­—å…¸
        :param output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä½¿ç”¨cot_dataç›®å½•ï¼‰
        :param max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼ˆé»˜è®¤3ï¼‰
        :param use_sandbox: æ˜¯å¦ä½¿ç”¨æ²™ç›’æ¨¡å¼ï¼ˆé»˜è®¤Trueï¼‰
        """
        self.config = config or {}
        self.max_workers = max_workers
        self.use_sandbox = use_sandbox  # é»˜è®¤å¯ç”¨æ²™ç›’
        
        # è®¾ç½®è¾“å‡ºç›®å½• - é»˜è®¤ä½¿ç”¨cot_dataç›®å½•
        if output_dir is None:
            # é»˜è®¤è¾“å‡ºåˆ°é¡¹ç›®æ ¹ç›®å½•/cot_data/æ—¶é—´æˆ³/
            output_dir = os.path.join(
                project_root,
                "cot_data",
                datetime.now().strftime("%Y%m%d_%H%M%S")
            )
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)
        
        print(f"ğŸš€ CoTæ•°æ®æ‰¹é‡ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"ğŸ”’ æ²™ç›’æ¨¡å¼: {'âœ… å¯ç”¨' if use_sandbox else 'âŒ ç¦ç”¨'}")
        print(f"ğŸ‘· å·¥ä½œçº¿ç¨‹: {max_workers}")
        
        # åˆå§‹åŒ–æ‰¹é‡è®°å½•å™¨
        self.batch_recorder = create_batch_cot_data_recorder(self.output_dir)
        
        # ä»»åŠ¡é˜Ÿåˆ—
        self.task_queue = Queue()
        self.results = []
        self.lock = threading.Lock()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_tasks": 0,
            "completed_tasks": 0,
            "successful_tasks": 0,
            "failed_tasks": 0,
            "total_steps": 0,
            "total_errors": 0,
            "start_time": None,
            "end_time": None
        }
    
    def load_tasks_from_file(self, filepath: str, fallback_to_default: bool = True) -> List[Dict[str, Any]]:
        """
        ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡åˆ—è¡¨
        
        :param filepath: ä»»åŠ¡æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰
        :param fallback_to_default: å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ˜¯å¦å›é€€åˆ°é»˜è®¤ä»»åŠ¡
        :return: ä»»åŠ¡åˆ—è¡¨
        """
        import os
        from pathlib import Path
        
        original_filepath = filepath
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(filepath):
            # å°è¯•åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹æŸ¥æ‰¾
            project_root = Path(__file__).parent.parent
            alternative_path = os.path.join(project_root, filepath)
            if os.path.exists(alternative_path):
                filepath = alternative_path
                print(f"ğŸ“„ ä½¿ç”¨é¡¹ç›®ç›¸å¯¹è·¯å¾„: {filepath}")
            else:
                # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ ¹æ®å‚æ•°å†³å®šè¡Œä¸º
                if fallback_to_default:
                    print(f"âš ï¸  ä»»åŠ¡æ–‡ä»¶ '{original_filepath}' ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨ä½¿ç”¨é»˜è®¤ä»»åŠ¡")
                    return self.load_default_tasks()
                else:
                    # æä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
                    raise FileNotFoundError(
                        f"âŒ ä»»åŠ¡æ–‡ä»¶ '{original_filepath}' ä¸å­˜åœ¨ã€‚\n\n"
                        f"ğŸ“‹ è§£å†³æ–¹æ¡ˆï¼š\n"
                        f"1. ä½¿ç”¨é»˜è®¤ä»»åŠ¡ï¼špython3 app/cot_data_generator_app.py --default-tasks\n"
                        f"2. åˆ›å»ºä»»åŠ¡æ–‡ä»¶ï¼ˆå‚è€ƒ example_tasks.json æ ¼å¼ï¼‰\n"
                        f"3. æŸ¥çœ‹å®Œæ•´å¸®åŠ©ï¼špython3 app/cot_data_generator_app.py --help\n\n"
                        f"ğŸ’¡ æç¤ºï¼šé¡¹ç›®æ ¹ç›®å½•å·²åˆ›å»º example_tasks.json ä½œä¸ºç¤ºä¾‹"
                    )
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                tasks_data = json.load(f)
        except json.JSONDecodeError as e:
            raise ValueError(f"ä»»åŠ¡æ–‡ä»¶ '{filepath}' æ ¼å¼é”™è¯¯ï¼ˆä¸æ˜¯æœ‰æ•ˆçš„JSONï¼‰: {e}")
        except Exception as e:
            raise IOError(f"è¯»å–ä»»åŠ¡æ–‡ä»¶ '{filepath}' å¤±è´¥: {e}")
        
        tasks = []
        if isinstance(tasks_data, list):
            for i, task_item in enumerate(tasks_data):
                if isinstance(task_item, str):
                    tasks.append({
                        "task_id": f"task_{i:04d}",
                        "mission": task_item,
                        "domain": "file-manager-extended"
                    })
                elif isinstance(task_item, dict):
                    task_id = task_item.get("task_id", f"task_{i:04d}")
                    mission = task_item.get("mission", "")
                    domain = task_item.get("domain", "file-manager-extended")
                    tasks.append({
                        "task_id": task_id,
                        "mission": mission,
                        "domain": domain
                    })
        elif isinstance(tasks_data, dict):
            # å•ä¸ªä»»åŠ¡
            tasks.append({
                "task_id": tasks_data.get("task_id", "task_0001"),
                "mission": tasks_data.get("mission", ""),
                "domain": tasks_data.get("domain", "file-manager-extended")
            })
        else:
            raise ValueError(f"ä»»åŠ¡æ–‡ä»¶ '{filepath}' æ ¼å¼é”™è¯¯ï¼šåº”ä¸ºåˆ—è¡¨æˆ–å­—å…¸ï¼Œå®é™…ä¸º {type(tasks_data)}")
        
        print(f"âœ… ä»æ–‡ä»¶åŠ è½½ {len(tasks)} ä¸ªä»»åŠ¡: {filepath}")
        return tasks
    
    def load_default_tasks(self) -> List[Dict[str, Any]]:
        """åŠ è½½é»˜è®¤æµ‹è¯•ä»»åŠ¡"""
        default_tasks = [
            "æ‰«æå½“å‰æ–‡ä»¶å¤¹",
            "åˆ›å»ºä¸€ä¸ªåä¸ºtestçš„æ–‡ä»¶å¤¹",
            "åˆ›å»ºåœ¨testæ–‡ä»¶å¤¹ï¼Œç„¶ååœ¨é‡Œé¢åˆ›å»ºREADME.mdæ–‡ä»¶",
            "å°†abc.txtæ–‡ä»¶é‡å‘½åä¸ºREADME.txt",
            "å¤åˆ¶abc.txtåˆ°backupæ–‡ä»¶å¤¹",
            "åˆ é™¤backupæ–‡ä»¶å¤¹",
            "å‹ç¼©backupæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶",
            "æŠŠæ‰€æœ‰æ–‡ä»¶å¤åˆ¶ä¸€ä»½ç„¶åæ‰“åŒ…æˆä¸€ä¸ªzipæ–‡ä»¶ï¼Œåå­—ä½ è‡ªå·±å–",
            "è·å–ç®¡ç†å‘˜æƒé™",
            "æ‰«æbackupæ–‡ä»¶å¤¹å¹¶åˆ›å»ºå¤‡ä»½",
            "é™¤äº†txtæ–‡ä»¶å¤–ï¼Œç§»åŠ¨æ‰€æœ‰æ–‡ä»¶åˆ°folder1æ–‡ä»¶å¤¹"
        ]
        
        tasks = []
        for i, mission in enumerate(default_tasks):
            tasks.append({
                "task_id": f"default_{i:04d}",
                "mission": mission,
                "domain": "file-manager-extended"
            })
        
        return tasks
    
    def add_task(self, task_id: str, mission: str, domain: str = "file-manager-extended"):
        """æ·»åŠ å•ä¸ªä»»åŠ¡åˆ°é˜Ÿåˆ—"""
        self.task_queue.put({
            "task_id": task_id,
            "mission": mission,
            "domain": domain
        })
        with self.lock:
            self.stats["total_tasks"] += 1
    
    def add_tasks(self, tasks: List[Dict[str, Any]]):
        """æ·»åŠ å¤šä¸ªä»»åŠ¡åˆ°é˜Ÿåˆ—"""
        for task in tasks:
            self.task_queue.put(task)
        with self.lock:
            self.stats["total_tasks"] += len(tasks)
    
    def _create_mock_llm(self):
        """åˆ›å»ºæ¨¡æ‹ŸLLMå®ä¾‹"""
        class MockLLM:
            def chat(self, messages, temperature=0.1):
                # æ ¹æ®æ¶ˆæ¯å†…å®¹è¿”å›ä¸åŒçš„æ¨¡æ‹Ÿå“åº”
                content = messages[-1]["content"] if messages else ""
                
                if "æ‰«æ" in content or "scan" in content.lower():
                    return "(scan root)"
                elif "åˆ›å»º" in content or "create" in content.lower():
                    return "(create_folder test)\n(create_file README.md)"
                elif "ç§»åŠ¨" in content or "move" in content.lower():
                    return "(move file1 root backup)"
                elif "é‡å‘½å" in content or "rename" in content.lower():
                    return "(rename file1 file2)"
                elif "å¤åˆ¶" in content or "copy" in content.lower():
                    return "(copy file1 root backup)"
                elif "åˆ é™¤" in content or "delete" in content.lower():
                    return "(remove file1)"
                elif "å‹ç¼©" in content or "compress" in content.lower():
                    return "(compress file1 archive.zip)"
                elif "è§£å‹" in content or "uncompress" in content.lower():
                    return "(uncompress archive.zip extracted)"
                else:
                    return "(scan root)\n(create_folder backup)\n(move file1 root backup)"
        
        return MockLLM()

    def _process_single_task(self, task_info: Dict[str, Any], llm_client, planner) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªä»»åŠ¡
        
        :param task_info: ä»»åŠ¡ä¿¡æ¯
        :param llm_client: LLMå®¢æˆ·ç«¯
        :param planner: è§„åˆ’å™¨
        :return: å¤„ç†ç»“æœ
        """
        task_id = task_info["task_id"]
        mission = task_info["mission"]
        domain = task_info.get("domain", "file-manager-extended")
        
        print(f"  [{task_id}] å¼€å§‹å¤„ç†: {mission}")
        
        try:
            # å¼€å§‹ä»»åŠ¡è®°å½•
            batch_recorder = self.batch_recorder.start_task(task_id, mission, domain)
            
            # åˆ›å»ºå¸¦è®°å½•å™¨çš„ç”Ÿæˆå™¨ï¼Œä½¿ç”¨batch_recorderä½œä¸ºè®°å½•å™¨
            generator = create_cot_data_generator_with_recorder(
                llm=llm_client,
                planner=planner,
                config={
                    "domain": domain,
                    "output_dir": os.path.join(self.output_dir, task_id)
                },
                recorder=batch_recorder  # ä½¿ç”¨batch_recorderä½œä¸ºè®°å½•å™¨
            )
            
            # ç”Ÿæˆæ•°æ®å¹¶è®°å½•
            result = generator.generate_with_recording(mission, save_to_file=False)
            
            # åœ¨ä¿å­˜å’Œé‡ç½®ä¹‹å‰æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
            task_stats = batch_recorder.get_statistics() if hasattr(batch_recorder, 'get_statistics') else {}
            
            # å®Œæˆä»»åŠ¡å¹¶ä¿å­˜æ•°æ®
            filename = f"cot_{task_id}_{int(time.time())}.json"
            filepath = self.batch_recorder.complete_task(task_id, filename)
            
            with self.lock:
                self.stats["completed_tasks"] += 1
                self.stats["successful_tasks"] += 1
                self.stats["total_steps"] += task_stats.get("total_steps", 0)
                self.stats["total_errors"] += task_stats.get("total_errors", 0)
            
            print(f"  [{task_id}] âœ… å¤„ç†æˆåŠŸ: {task_stats.get('total_steps', 0)} æ­¥éª¤, "
                  f"{task_stats.get('total_errors', 0)} é”™è¯¯")
            
            return {
                "task_id": task_id,
                "success": True,
                "mission": mission,
                "filepath": filepath,
                "statistics": task_stats,
                "error": None
            }
            
        except Exception as e:
            with self.lock:
                self.stats["completed_tasks"] += 1
                self.stats["failed_tasks"] += 1
            
            print(f"  [{task_id}] âŒ å¤„ç†å¤±è´¥: {e}")
            
            return {
                "task_id": task_id,
                "success": False,
                "mission": mission,
                "filepath": None,
                "statistics": {},
                "error": str(e)
            }
    
    def run(self, use_mock_llm: bool = False, llm_api_key: Optional[str] = None):
        """
        è¿è¡Œæ‰¹é‡ç”Ÿæˆ
        
        :param use_mock_llm: æ˜¯å¦ä½¿ç”¨æ¨¡æ‹ŸLLMï¼ˆç”¨äºæµ‹è¯•ï¼‰ï¼Œé»˜è®¤Falseï¼ˆä½¿ç”¨çœŸå®LLMï¼‰
        :param llm_api_key: LLM APIå¯†é’¥ï¼ˆå¦‚æœä¸ä½¿ç”¨æ¨¡æ‹ŸLLMï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡åŠ è½½
        """
        print("=" * 60)
        print("ğŸš€ CoTæ•°æ®æ‰¹é‡ç”Ÿæˆå™¨å¯åŠ¨")
        print("=" * 60)
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"æœ€å¤§å·¥ä½œçº¿ç¨‹: {self.max_workers}")
        print(f"æ€»ä»»åŠ¡æ•°: {self.stats['total_tasks']}")
        print("-" * 60)
        
        self.stats["start_time"] = datetime.now()
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯å’Œè§„åˆ’å™¨
        llm_client = None
        planner = None
        
        # å¦‚æœæ˜ç¡®è¦æ±‚ä½¿ç”¨æ¨¡æ‹ŸLLM
        if use_mock_llm:
            print("ä½¿ç”¨æ¨¡æ‹ŸLLMï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰")
            llm_client = self._create_mock_llm()
            planner = None
        else:
            print("ä½¿ç”¨çœŸå®LLMï¼ˆç”Ÿäº§æ¨¡å¼ï¼‰")
            
            # å°è¯•è·å–APIå¯†é’¥
            final_api_key = llm_api_key
            if not final_api_key:
                try:
                    # ä»ç¯å¢ƒå˜é‡åŠ è½½
                    settings = Settings.load_from_env()
                    final_api_key = settings.llm_api_key
                    
                    if not final_api_key or final_api_key == "your-api-key":
                        print("âš ï¸  è­¦å‘Š: ç¯å¢ƒå˜é‡ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„LLM APIå¯†é’¥")
                        print("ğŸ’¡ å»ºè®®: è¯·è®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨ --api-key å‚æ•°")
                        print("ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°æ¨¡æ‹ŸLLMæ¨¡å¼")
                        llm_client = self._create_mock_llm()
                        planner = None
                    else:
                        print(f"âœ… ä»ç¯å¢ƒå˜é‡åŠ è½½APIå¯†é’¥æˆåŠŸï¼ˆå¯†é’¥é•¿åº¦: {len(final_api_key)}ï¼‰")
                except Exception as e:
                    print(f"âš ï¸  åŠ è½½ç¯å¢ƒé…ç½®å¤±è´¥: {e}")
                    print("ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°æ¨¡æ‹ŸLLMæ¨¡å¼")
                    llm_client = self._create_mock_llm()
                    planner = None
            
            # å¦‚æœä»ç„¶æ²¡æœ‰LLMå®¢æˆ·ç«¯ï¼ˆè¯´æ˜éœ€è¦åˆ›å»ºçœŸå®LLMï¼‰
            if not llm_client and final_api_key:
                try:
                    # åŠ è½½é…ç½®
                    settings = Settings.load_from_env()
                    settings.llm_api_key = final_api_key
                    
                    # åˆ›å»ºçœŸå®LLMå®¢æˆ·ç«¯
                    llm_client = DeepSeekClient(
                        api_key=settings.llm_api_key,
                        base_url=settings.llm_base_url,
                        model=settings.llm_model
                    )
                    
                    # åˆ›å»ºè§„åˆ’å™¨
                    planner = LAMAPlanner(config=settings)
                    print("âœ… çœŸå®LLMå®¢æˆ·ç«¯å’Œè§„åˆ’å™¨åˆ›å»ºæˆåŠŸ")
                except Exception as e:
                    print(f"âŒ åˆ›å»ºçœŸå®LLMå®¢æˆ·ç«¯å¤±è´¥: {e}")
                    print("ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°æ¨¡æ‹ŸLLMæ¨¡å¼")
                    llm_client = self._create_mock_llm()
                    planner = None
        
        # ç¡®ä¿æœ‰LLMå®¢æˆ·ç«¯ï¼ˆå…œåº•ï¼‰
        if not llm_client:
            print("âš ï¸  LLMå®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹ŸLLMä½œä¸ºå…œåº•")
            llm_client = self._create_mock_llm()
            planner = None
        
        # æ”¹ä¸ºä¸²è¡Œå¤„ç†ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
        print("ğŸ“Š ä½¿ç”¨ä¸²è¡Œå¤„ç†æ¨¡å¼ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰")
        
        # æ”¶é›†æ‰€æœ‰ä»»åŠ¡åˆ°åˆ—è¡¨
        task_list = []
        while not self.task_queue.empty():
            task_info = self.task_queue.get()
            task_list.append(task_info)
        
        # ä¸²è¡Œå¤„ç†æ¯ä¸ªä»»åŠ¡
        total_tasks = len(task_list)
        for i, task_info in enumerate(task_list):
            task_num = i + 1
            print(f"\nğŸ“‹ å¤„ç†ä»»åŠ¡ {task_num}/{total_tasks}: {task_info['task_id']}")
            
            try:
                result = self._process_single_task(task_info, llm_client, planner)
                self.results.append(result)
            except Exception as e:
                print(f"âŒ ä»»åŠ¡ {task_info['task_id']} æ‰§è¡Œå¼‚å¸¸: {e}")
                # è®°å½•å¤±è´¥ç»“æœ
                self.results.append({
                    "task_id": task_info["task_id"],
                    "success": False,
                    "mission": task_info["mission"],
                    "filepath": None,
                    "statistics": {},
                    "error": str(e)
                })
                with self.lock:
                    self.stats["completed_tasks"] += 1
                    self.stats["failed_tasks"] += 1
        
        # æ³¨é‡Šï¼šåŸå¹¶è¡Œä»£ç ï¼ˆä¿ç•™ä»¥å¤‡å°†æ¥æ¢å¤ï¼‰
        # # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†ä»»åŠ¡
        # with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
        #     futures = []
        #
        #     # æäº¤æ‰€æœ‰ä»»åŠ¡
        #     while not self.task_queue.empty():
        #         task_info = self.task_queue.get()
        #         future = executor.submit(self._process_single_task, task_info, llm_client, planner)
        #         futures.append(future)
        #
        #     # æ”¶é›†ç»“æœ
        #     for future in concurrent.futures.as_completed(futures):
        #         try:
        #             result = future.result()
        #             self.results.append(result)
        #         except Exception as e:
        #             print(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
        
        # æ›´æ–°ç»“æŸæ—¶é—´
        self.stats["end_time"] = datetime.now()
        
        # ç”ŸæˆæŠ¥å‘Š
        self._generate_report()
    
    def _generate_report(self):
        """ç”Ÿæˆå¤„ç†æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æ‰¹é‡å¤„ç†æŠ¥å‘Š")
        print("=" * 60)
        
        # è®¡ç®—è€—æ—¶
        if self.stats["start_time"] and self.stats["end_time"]:
            duration = self.stats["end_time"] - self.stats["start_time"]
            print(f"æ€»è€—æ—¶: {duration}")
        
        print(f"æ€»ä»»åŠ¡æ•°: {self.stats['total_tasks']}")
        print(f"å·²å®Œæˆä»»åŠ¡: {self.stats['completed_tasks']}")
        print(f"æˆåŠŸä»»åŠ¡: {self.stats['successful_tasks']}")
        print(f"å¤±è´¥ä»»åŠ¡: {self.stats['failed_tasks']}")
        
        if self.stats['completed_tasks'] > 0:
            success_rate = (self.stats['successful_tasks'] / self.stats['completed_tasks']) * 100
            print(f"æˆåŠŸç‡: {success_rate:.1f}%")
        
        print(f"æ€»æ­¥éª¤æ•°: {self.stats['total_steps']}")
        print(f"æ€»é”™è¯¯æ•°: {self.stats['total_errors']}")
        
        if self.stats['total_steps'] > 0:
            error_rate = (self.stats['total_errors'] / (self.stats['total_steps'] + self.stats['total_errors'])) * 100
            print(f"é”™è¯¯ç‡: {error_rate:.1f}%")
        
        # æ‰¹é‡è®°å½•å™¨æ‘˜è¦
        batch_summary = self.batch_recorder.get_summary()
        print(f"\nğŸ“¦ æ•°æ®è®°å½•æ‘˜è¦:")
        print(f"  æ€»æ•°æ®ç‚¹: {batch_summary.get('total_tasks', 0)}")
        print(f"  æ€»æ­¥éª¤: {batch_summary.get('total_steps', 0)}")
        print(f"  æ€»é”™è¯¯: {batch_summary.get('total_errors', 0)}")
        print(f"  æˆåŠŸç‡: {batch_summary.get('success_rate', 0):.1f}%")
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_file = os.path.join(self.output_dir, "batch_report.json")
        
        # å‡†å¤‡æŠ¥å‘Šæ•°æ®ï¼Œç¡®ä¿æ‰€æœ‰datetimeå¯¹è±¡éƒ½è¢«è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        stats_copy = self.stats.copy()
        if stats_copy.get("start_time") and isinstance(stats_copy["start_time"], datetime):
            stats_copy["start_time"] = stats_copy["start_time"].isoformat()
        if stats_copy.get("end_time") and isinstance(stats_copy["end_time"], datetime):
            stats_copy["end_time"] = stats_copy["end_time"].isoformat()
        
        report_data = {
            "stats": stats_copy,
            "batch_summary": batch_summary,
            "results_summary": [
                {
                    "task_id": r["task_id"],
                    "success": r["success"],
                    "mission": r["mission"],
                    "filepath": r["filepath"]
                }
                for r in self.results
            ],
            "output_dir": self.output_dir,
            "generated_at": datetime.now().isoformat()
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        # å¯¼å‡ºæ‰€æœ‰è®­ç»ƒæ•°æ®
        try:
            exported = self.batch_recorder.export_all_training_data()
            print(f"\nğŸ¯ è®­ç»ƒæ•°æ®å·²å¯¼å‡º:")
            print(f"  BrainLLMæ•°æ®: {len(exported.get('brain_files', []))} ä¸ªæ–‡ä»¶")
            print(f"  NervesLLMæ•°æ®: {len(exported.get('nerves_files', []))} ä¸ªæ–‡ä»¶")
            print(f"  AnalysisLLMæ•°æ®: {len(exported.get('analysis_files', []))} ä¸ªæ–‡ä»¶")
        except Exception as e:
            print(f"\nâš ï¸  è®­ç»ƒæ•°æ®å¯¼å‡ºå¤±è´¥: {e}")
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰¹é‡ç”Ÿæˆå®Œæˆ!")
        print("=" * 60)
    
    def get_results(self) -> List[Dict[str, Any]]:
        """è·å–å¤„ç†ç»“æœ"""
        return self.results
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats


def main():
    """å‘½ä»¤è¡Œä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="CoTæ•°æ®æ‰¹é‡ç”Ÿæˆå·¥å…· - è‡ªåŠ¨åŒ–ç”ŸæˆChain-of-Thoughtè®­ç»ƒæ•°æ®",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ä½¿ç”¨é»˜è®¤ä»»åŠ¡ï¼ˆæ¨èæ–°æ‰‹ï¼‰- è‡ªåŠ¨å°è¯•ä½¿ç”¨çœŸå®LLMï¼ˆä»ç¯å¢ƒå˜é‡åŠ è½½ï¼‰
  python3 app/cot_data_generator_app.py --default-tasks
  
  # ä½¿ç”¨è‡ªå®šä¹‰ä»»åŠ¡æ–‡ä»¶
  python3 app/cot_data_generator_app.py --tasks-file tasks.json
  
  # ä½¿ç”¨ç¤ºä¾‹ä»»åŠ¡æ–‡ä»¶
  python3 app/cot_data_generator_app.py --tasks-file example_tasks.json
  
  # å¼ºåˆ¶ä½¿ç”¨çœŸå®LLMï¼ˆéœ€è¦APIå¯†é’¥ï¼‰
  python3 app/cot_data_generator_app.py --default-tasks --use-real-llm --api-key YOUR_KEY
  
  # å¼ºåˆ¶ä½¿ç”¨æ¨¡æ‹ŸLLMï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰
  python3 app/cot_data_generator_app.py --default-tasks --use-mock-llm
  
  # è‡ªå®šä¹‰è¾“å‡ºç›®å½•å’Œå·¥ä½œçº¿ç¨‹
  python3 app/cot_data_generator_app.py --default-tasks --output-dir ./my_data --workers 5

ä»»åŠ¡æ–‡ä»¶æ ¼å¼:
  æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
  1. å­—ç¬¦ä¸²åˆ—è¡¨: ["ä»»åŠ¡1", "ä»»åŠ¡2", ...]
  2. å¯¹è±¡åˆ—è¡¨: [{"task_id": "id1", "mission": "ä»»åŠ¡1", "domain": "file-manager-extended"}, ...]

ç¤ºä¾‹æ–‡ä»¶: example_tasks.json
        """
    )
    parser.add_argument("--tasks-file", type=str, help="ä»»åŠ¡æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰ï¼Œæ”¯æŒç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„")
    parser.add_argument("--output-dir", type=str, help="è¾“å‡ºç›®å½•ï¼Œé»˜è®¤: ./cot_data/æ—¶é—´æˆ³/")
    parser.add_argument("--workers", type=int, default=3, help="å·¥ä½œçº¿ç¨‹æ•°ï¼Œé»˜è®¤: 3")
    parser.add_argument("--use-mock-llm", action="store_true", help="å¼ºåˆ¶ä½¿ç”¨æ¨¡æ‹ŸLLMï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰ï¼Œé»˜è®¤å°è¯•ä½¿ç”¨çœŸå®LLM")
    parser.add_argument("--use-real-llm", action="store_true", help="å¼ºåˆ¶ä½¿ç”¨çœŸå®LLMï¼ˆéœ€è¦APIå¯†é’¥ï¼‰ï¼Œé»˜è®¤å°è¯•ä»ç¯å¢ƒå˜é‡åŠ è½½")
    parser.add_argument("--api-key", type=str, help="LLM APIå¯†é’¥ï¼ˆå¼ºåˆ¶ä½¿ç”¨çœŸå®LLMæ—¶å¿…éœ€ï¼Œå¦åˆ™ä»ç¯å¢ƒå˜é‡åŠ è½½ï¼‰")
    parser.add_argument("--default-tasks", action="store_true", help="ä½¿ç”¨é»˜è®¤æµ‹è¯•ä»»åŠ¡ï¼ˆ14ä¸ªé¢„å®šä¹‰ä»»åŠ¡ï¼‰")
    
    args = parser.parse_args()
    
    # éªŒè¯å‚æ•°
    if args.use_real_llm and not args.api_key:
        print("âŒ é”™è¯¯: ä½¿ç”¨çœŸå®LLMæ—¶å¿…é¡»æä¾› --api-key å‚æ•°")
        parser.print_help()
        return
    
    # åˆ›å»ºæ‰¹é‡ç”Ÿæˆå™¨
    try:
        generator = CoTDataBatchGenerator(
            output_dir=args.output_dir,
            max_workers=args.workers
        )
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–æ‰¹é‡ç”Ÿæˆå™¨å¤±è´¥: {e}")
        return
    
    # åŠ è½½ä»»åŠ¡
    try:
        if args.tasks_file:
            print(f"ğŸ“„ ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡: {args.tasks_file}")
            # ä¸è‡ªåŠ¨å›é€€ï¼Œè®©ç”¨æˆ·æ˜ç¡®çŸ¥é“æ–‡ä»¶ä¸å­˜åœ¨
            tasks = generator.load_tasks_from_file(args.tasks_file, fallback_to_default=False)
            generator.add_tasks(tasks)
        elif args.default_tasks:
            print("ğŸ“‹ ä½¿ç”¨é»˜è®¤æµ‹è¯•ä»»åŠ¡")
            tasks = generator.load_default_tasks()
            generator.add_tasks(tasks)
        else:
            print("âŒ é”™è¯¯: å¿…é¡»æä¾›ä»»åŠ¡æº")
            print("\nğŸ’¡ è¯·é€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€:")
            print("  1. ä½¿ç”¨é»˜è®¤ä»»åŠ¡: --default-tasks")
            print("  2. ä½¿ç”¨ä»»åŠ¡æ–‡ä»¶: --tasks-file <æ–‡ä»¶è·¯å¾„>")
            print("  3. æŸ¥çœ‹å®Œæ•´å¸®åŠ©: --help")
            print("\nğŸ“ æç¤º: é¡¹ç›®æ ¹ç›®å½•å·²åˆ›å»º example_tasks.json ä½œä¸ºç¤ºä¾‹")
            return
    except FileNotFoundError as e:
        print(f"\nâŒ {e}")
        return
    except (ValueError, IOError) as e:
        print(f"âŒ åŠ è½½ä»»åŠ¡å¤±è´¥: {e}")
        return
    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # è¿è¡Œæ‰¹é‡ç”Ÿæˆ
    # ç¡®å®šLLMæ¨¡å¼
    if args.use_mock_llm:
        # ç”¨æˆ·æ˜ç¡®è¦æ±‚ä½¿ç”¨æ¨¡æ‹ŸLLM
        use_mock_llm = True
        llm_api_key = None
        print("ğŸ”§ ç”¨æˆ·æŒ‡å®šä½¿ç”¨æ¨¡æ‹ŸLLMï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰")
    elif args.use_real_llm:
        # ç”¨æˆ·æ˜ç¡®è¦æ±‚ä½¿ç”¨çœŸå®LLM
        use_mock_llm = False
        llm_api_key = args.api_key
        print("ğŸ”§ ç”¨æˆ·æŒ‡å®šä½¿ç”¨çœŸå®LLMï¼ˆç”Ÿäº§æ¨¡å¼ï¼‰")
    else:
        # é»˜è®¤ï¼šå°è¯•ä½¿ç”¨çœŸå®LLMï¼ˆä»ç¯å¢ƒå˜é‡åŠ è½½ï¼‰
        use_mock_llm = False
        llm_api_key = args.api_key  # å¯èƒ½ä¸ºNoneï¼Œrun()æ–¹æ³•ä¼šä»ç¯å¢ƒå˜é‡åŠ è½½
        print("ğŸ”§ é»˜è®¤æ¨¡å¼ï¼šå°è¯•ä½¿ç”¨çœŸå®LLMï¼ˆä»ç¯å¢ƒå˜é‡åŠ è½½APIå¯†é’¥ï¼‰")
    
    print("\n" + "=" * 60)
    print("ğŸš€ å¼€å§‹æ‰¹é‡æ•°æ®ç”Ÿæˆ")
    print("=" * 60)
    
    try:
        generator.run(use_mock_llm=use_mock_llm, llm_api_key=llm_api_key)
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œåœæ­¢æ‰¹é‡ç”Ÿæˆ")
    except Exception as e:
        print(f"\nâŒ æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def quick_test():
    """å¿«é€Ÿæµ‹è¯•å‡½æ•°"""
    print("è¿è¡Œå¿«é€Ÿæµ‹è¯•...")
    
    # åˆ›å»ºæ‰¹é‡ç”Ÿæˆå™¨ - ä½¿ç”¨cot_dataç›®å½•è€Œä¸æ˜¯workspace
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = os.path.join(project_root, "cot_data", f"test_{timestamp}")
    
    generator = CoTDataBatchGenerator(
        output_dir=output_dir,
        max_workers=2
    )
    
    # æ·»åŠ å‡ ä¸ªæµ‹è¯•ä»»åŠ¡
    test_tasks = [
        {"task_id": "test_001", "mission": "æ‰«æworkspaceæ–‡ä»¶å¤¹", "domain": "file-manager-extended"},
        {"task_id": "test_002", "mission": "åˆ›å»ºtestæ–‡ä»¶å¤¹", "domain": "file-manager-extended"},
        {"task_id": "test_003", "mission": "ç§»åŠ¨æ–‡ä»¶åˆ°backup", "domain": "file-manager-extended"},
    ]
    
    generator.add_tasks(test_tasks)
    
    # è¿è¡Œæµ‹è¯•ï¼ˆä½¿ç”¨æ¨¡æ‹ŸLLMï¼‰
    print("ä½¿ç”¨æ¨¡æ‹ŸLLMè¿è¡Œæµ‹è¯•...")
    generator.run(use_mock_llm=True)
    
    # æ˜¾ç¤ºç»“æœ
    results = generator.get_results()
    print(f"\næµ‹è¯•å®Œæˆï¼Œå¤„ç†äº† {len(results)} ä¸ªä»»åŠ¡")
    
    for result in results:
        status = "âœ… æˆåŠŸ" if result["success"] else "âŒ å¤±è´¥"
        print(f"  {result['task_id']}: {status} - {result['mission']}")
    
    return generator


if __name__ == "__main__":
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œè¿è¡Œå¿«é€Ÿæµ‹è¯•
    if len(sys.argv) == 1:
        print("æœªæä¾›å‘½ä»¤è¡Œå‚æ•°ï¼Œè¿è¡Œå¿«é€Ÿæµ‹è¯•...")
        quick_test()
    else:
        main()